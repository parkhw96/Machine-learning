## Machine Learning System Design



- ### Prioritizing what to work on - spam classification example

  ##### ![content_11(1)](img/content_11(1).PNG)

  ##### 왼쪽 같은 이메일은 잘못된 철자가 들어있는 스팸 이메일이고, 오른쪽 같은 이메일은 일반 이메일이다. 

  ##### 스팸 이메일은 y = 1로, 일반 이메일은 y = 0으로 가정한다면, 어떻게 스팸 이메일과 일반 이메일은 구별할 수 있을까?

  ##### 첫번째 접근 방법으로는 스팸인지 아닌지를 지시하는 100개의 단어들을 고르는 것이다. 예를 들어 스팸 이메일 같은 경우 buy, discount, deal 같은 단어들이 있고, 일반 이메일은 Andrew, now같은 단어들이 있다.

  ##### 이러한 모든 단어들을 하나의 긴 벡터로 만든다.(reference vector로 인코딩한다.)

  ##### ![content_11(2)](img/content_11(2).PNG)

  ##### 위와 같이 feature vector x를 정의하는데, 특정 단어가 있는지 없는지의 여부에 따라 feature vector에 0과 1을 표시한다. 단, 똑같은 단어가 여러번 나와도 1로 표시한다.

  ##### 그렇다면 시스템의 정확도를 높이기 위해서는 어떻게 해야 할까?

  ##### 데이터를 많이 수집한다.(예 : honey pot anti-spam projects) 그러나 항상 데이터를 많이 수집하는 것은 도움이 되지 않는다.

  ##### 이메일 라우팅 정보(email header)를 기반으로 정교한 features들을 개발한다. spammer들은 종종 이메일의 출처를 모호하게 표시하고, 흔치 않은 경로를 통해 보낸다. 이러한 것들이 email header에 남기 때문에 이메일 라우팅 정보를 캡처하는 정교한 features들을 개발할 필요가 있다.

  ##### 이메일의 본문 분석에 대해 정교한 features들을 개발한다. Discount와 discounts를 같은 단어로 취급할지, deal과 DEAL를 같은 단어로 취급할지와 같은 것들이 해당된다.

  ##### 틀린 철자를 감지하기 위해 정교한 알고리즘을 개발한다. spammer들은 감지 시스템에 걸리지 않기 위해 잘못 표기된 철자를 사용한다.

  - #### Error analysis

    ##### 스팸 분류기를 만들 때 cross validation set에서 알고리즘이 오류를 일으키는 이메일들을 직접 점검한다.

    ##### ![content_11(3)](img/content_11(3).PNG)

    ##### 위와 같이 500개의 CV set을 가지고 있는 스팸 분류기를 만들었다. 그러나 100개의 오류가 나므로 오류율이 높다.

    ##### 그러면, 그 오류가 난 100개의 이메일을 직접 검사하고 분류한다. 그 이메일들은 약국 이메일, 피싱 이메일 등등으로 분류된다.

    ##### 여기서는 비밀번호를 훔치려는 피싱 이메일을 잘 분류하지 못한다.(100개 중에 53개 이므로) 그러므로 그 53개의 피싱 이메일을 더 잘 처리할 수 있는 feature를 찾기 위해 세부적으로 분석한다. 그 53개의 이메일은 5개의 고의적인 맞춤법 오류, 16개의 흔치 않은 이메일 라우팅, 32개의 흔치않은 구두법으로 나뉜다. 

    ##### 32개의 흔치 않은 구두법의 갯수가 가장 많기 때문에 이것을 기반으로 스팸 분류기를 보강한다면 더 좋은 결과를 얻을 수 있을 것이다.

  - #### numerical evaluation의 중요성

    ##### 만일 알고리즘을 개발한다면, 그것이 얼마나 잘 작동하는지를 말해주는 것으로써의 성능 계산을 하나의 숫자로 나타내는 것은 좋다.

    ##### 예를 들어, 비슷한 단어를 같은 단어로 취급해야할지를 결정하는 것이 있다.

    ##### 이러한 경우에는 NLP의 stemming을 사용할 수 있다. 이 방법은 알고리즘을 좋게 만들거나 나쁘게 만들 수 있다.

    ##### 그래서 가장 좋은 방법은 stemming을 빠르게 적용하여 결과를 확인하는 것이다. 예를 들어 stemming을 적용하였을 때에는 3%의 오류, 적용하지 않았을 때는 5%의 오류가 발생한다면 stemming을 사용하는 것이 좋다고 판단할 수 있다.

---



- ### Error metrics for skewed analysis

  ##### Cancer classification을 예로 들면, 암이 있으면 y = 1, 없으면 y = 0으로 logistic regression 모델을 학습시킨다.

  ##### test set에서 1%의 오류를 얻었다고 하면 이것은 되게 좋아 보인다. 하지만 실제로는 0.5%의 환자만이 암에 걸렸다. 이것은 선별된 환자 중에 절반은 정상이고 절반은 암에 걸렸다는 의미이다. 따라서 여기서 1%의 오류는 좋지 않아 보인다.

  ##### 그렇다면 간단한 코드로 y = 0으로만 예측하게 만든다면, 이때에는 0.5%의 오류를 얻게 된다.(실제로 암이 걸린 사람이 0,5%이기 때문에)

  ##### 즉, 왜곡된 클래스(skewed class)는 긍정적인 예제와 부정적인 예제의 비율이 어느 한쪽으로 매우 치우진 예제를 의미한다.

  - #### Precision and recall

    ##### 한쪽으로 치우친 왜곡된 클래스를 평가할 때 정확도 외에 다른 오류 지표나 평가 지표가 필요하다. 왜냐하면 위의 예에서처럼 정확도로만 평가를 하게 되면 좋지 않은 결과를 내기 때문이다.

    ##### ![content_11(4)](img/content_11(4).PNG)

    ##### 정확도(Precision)는 암이라고 예측한 모든 환자중에서 실제로 암에 걸린 환자의 비율을 나타낸다. 즉, 암을 분류하는 것의 정확도는 (실제 암에 걸린 환자 수) / (예측된 암에 걸린 환자 수)이다.

    ##### ![content_11(5)](img/content_11(5).PNG)

    ##### 즉, 1행의  두 항목을 다 더한 것이 분모로 가게 되고, 분자는 true positive가 된다.(전체 positive 중의 실제 positive)

    ##### 정확도는 높을수록 좋다.

    ##### 재현율(Recall)은 실제 암에 걸린 환자 중에서 암이라고 예측한 환자의 비율이다. 즉, 정확히 예측한 비율이다.  (암환자라고 예측한 수) / (실제로 암에 걸린 환자 수)

    ##### ![content_11(6)](img/content_11(6).PNG)

    ##### 분모는 첫번째 열에 있는 두 항목을 더한 것이다.

    ##### 재현율은 높을수록 좋다. 따라서, 정확도와 재현율은 분류기가 얼마나 잘 동작하는지를 알려주는 지표이다.

---



- ### Trading off precision and recall

  ##### 많은 응용에 대해서 우리는 precision과 recall의 trade-off를 잘 조절해야 한다.

  ##### 평소와 같이 logistic regression classifier를 $h_\theta(x)$ >= 0.5이면 1로 예측하고 아니면 0으로 예측한다.

  ##### 하지만 이번에는 환자가 암에 확실히 걸렸다고 믿을 수 있을때 y=1을 예측한다고 해보자.

  ##### 그래서 임계값을 0.5가 아닌 0.8로 바꾼다. 그러면 $h_\theta(x)$ >= 0.8이면 1로 예측하고 아니면 0으로 예측한다.

  ##### 그렇게되면 정확도는 높아지게 되지만, 재현율은 낮아지게 된다. 왜냐하면 암이라고 예측한 환자수(분자 값)가 적어지기 때문이다.

  ##### 반대로 임계값은 0.3으로 바꾼다면 재현율은 높아지게 되지만, 정확도는 낮아지게 된다.

  ##### ![content_11(7)](img/content_11(7).PNG)

  ##### 위와 같이 임계값을 무엇으로 바꾸냐에 따라 정확도와 재현율이 달라진다.

  ##### 정확도와 재현율을 그래프로 그릴 수 있다.

  ##### ![content_11(8)](img/content_11(8).PNG)

  ##### 임계값이 크다면 정확도는 높지만 재현율은 낮고, 임계값이 작다면 정확도는 낮지만 재현율은 높다.

  ##### ![content_11(9)](img/content_11(9).PNG)

  ##### 이 알고리즘 중에 어떤 것이 가장 좋다고 판단할 수 있을까?

  ##### 첫번째 방법으로는 (P + R) / 2와 같이 평균을 구하는 것이다.

  ##### 첫번째 방법으로 평균을 구해보면 차례대로 0.45, 0.4, 0.51이 나와서 0.51이 가장 좋다고 할 수 있다. 하지만 0.51이 나온 Algorithm 3의 재현율은 1이다. 즉, 모든 것을 y=1으로만 예측하겠다는 의미이다. 그래서 첫번째 방법과 같이 평균을 구하는 방법은 좋지 않다.

  ##### 두번째 방법은 2 * (PR / [P + R])와 같이 Fscore를 구하는 것이다. 이 방법으로 구해보면 각각 0.444, 0.175, 0.392가 나와 0.444가 좋다고 할 수 있다. 즉, Fscore의 분자는 정확도와 재현율을 곱하기 때문에 어느 한쪽이 0이거나 0에 가까울 때 Fscore는 0에 가까운 값이 된다.

  ##### 그러므로 여러가지의 임계값을 설정하여 정확도와 재현율의 값을 얻고, 그 정확도와 재현율의 값을 통해 Fscore를 얻어 가장 큰 Fscore인 임계값을 설정하는 방법을 선택한다. 이것이 분류기가 임계값을 자동으로 선택하는 합리적인 방법이다.

---



- ### Data for machine learning

  ##### ![content_11(10)](img/content_11(10).PNG)

  ##### 위와 같이 결과를 통해 training set 사이즈가 증가하면 accuracy도 증가하는 것을 알 수 있다.

  ##### 엄청난 양의 데이터를 가지는 것이 알고리즘을 성능을 향상시킨다고 하였는데 이것이 언제는 사실이고 언제는 거짓일까?

  ##### feature x가 y를 정확히 예측하는데 충분한 정보를 가지고 있다고 하면 더 많은 데이터는 도움이 될 것이다. 예를 들어 "For breakfast I ate ___ eggs"에 들어갈 단어는 to, too, two 등으로 혼동할 수 있다. 이 때 x는 공백 주변의 단어를 수집한다. 그러면 빈칸에 들어갈 단어는 to, too가 아닌 two일 것이다. 즉, 알고리즘이 빈칸 주변의 단어에 대한 충분한 정보를 수집한다면 y또는 혼동할  수 있는 세 단어 중에서 공백의 단어를 결정할 수 있다.

  ##### 반대의 경우에는 주택 크기만으로 주택 가격을 예측하는 문제가 있다고 해보자. 그렇다면 주택 크기만으로는 주택 가격을 정확히 예측하기 어렵다.(방이 몇개 있는지, 신축인지 구축인지 등등을 모르기 때문에)

  ##### 따라서 feature가 충분한 정보를 제공한다면 데이터가 많을 수록 알고리즘의 성능을 개선할 수 있다. 

  ##### logistic regression 또는 linear regression과 같이 수많은 feature들을 가지거나, 또한 많은 hidden feature들을 가진 neural network와 같이 많은 parameter들을 가진 학습 알고리즘들을 사용한다. 이러한 것들은 매우 복잡한 함수에 적합한 수많은 parameter들을 가진 강력한 학습 알고리즘들이다. 

  ##### 또한 이러한 알고리즘들을 low bias 알고리즘이라고 한다. 

  ##### 만일 이러한 알고리즘들에 적은 양의 training set을 사용한다면 training error는 적을 것이다. 그렇다면 많은 양의 training set을 사용한다면(parameter들이 많음) overfitting이 발생하지 않는다.

  ##### 이렇게 많은 양의 training set은 overfitting을 방지하기 때문에 training error는 매우 작을 것이고 또한 test error도 작을 것이다. 

  ##### 우리는 low bias와 low variance인 알고리즘을 얻는 것을 원한다. low bias는 복잡한 알고리즘을 사용하고, low variance는 많은 training set을 사용함으로써 얻을 수 있다. 즉 이 2가지 방법을 결합하면 low bias와 low variance를 가진 알고리즘을 얻을 수 있다.

